name: CI

on: [push, pull_request]

env:
  PIP_CACHE: ~/.cache/pip
  INDEX_DIR: data/index
  ENABLE_DENSE: "0"
  AE_BIND_PORT: "8001"
  CONCEPT_MIN_SCORE: "0.05"

jobs:
  test-api:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      PYTHONUNBUFFERED: "1"
      PYTHONHASHSEED: "0"
      ENVIRONMENT: "development"
      DEBUG: "true"
      ENABLE_DENSE: "0"
      AE_BIND_PORT: "8001"
      AE_INDEX_DIR: "${{ github.workspace }}/data/index"
      AE_CACHE_ENABLED: "0"
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install (editable + test deps)
        run: |
          python -m pip install -U pip
          python -m pip install -c constraints/ci.txt -e .
          python -m pip install -c constraints/ci.txt pytest httpx

      - name: Prepare index
        run: |
          set -euo pipefail
          ./scripts/sync_rfc_min.sh
          python scripts/build_index.py
          ls -l data/index || true

      - name: Run smoke tests
        run: python -m pytest -q tests/ci_smoke_test.py -o log_cli=true -o log_cli_level=INFO -rA --maxfail=1 --disable-warnings | tee ci_pytest_smoke.log

      - name: Upload smoke test log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci_smoke_log
          path: ci_pytest_smoke.log

  ci-full:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: test-api
    continue-on-error: true
    env:
      PYTHONUNBUFFERED: "1"
      PYTHONHASHSEED: "0"
      ENVIRONMENT: "development"
      DEBUG: "true"
      ENABLE_DENSE: "0"
      AE_BIND_PORT: "8001"
      AE_INDEX_DIR: "${{ github.workspace }}/data/index"
      AE_CACHE_ENABLED: "0"
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install (editable + test deps)
        run: |
          python -m pip install -U pip
          python -m pip install -c constraints/ci.txt -e .
          python -m pip install -c constraints/ci.txt pytest httpx

      - name: Prepare index
        run: |
          set -euo pipefail
          ./scripts/sync_rfc_min.sh
          python scripts/build_index.py

      - name: Run full test suite
        run: python -m pytest -q -o log_cli=true -o log_cli_level=INFO -rA --maxfail=1 --disable-warnings | tee ci_pytest_full.log

  eval:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: test-api
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ env.PIP_CACHE }}
          key: pip-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}

      - name: Install (editable + eval deps)
        run: |
          python -m pip install -U pip
          python -m pip install -c constraints/ci.txt -e .
          python -m pip install -c constraints/ci.txt pydantic-settings
          python -c "import pydantic_settings; print('pydantic-settings:', pydantic_settings.__version__)"

      - name: Cache RFC index
        uses: actions/cache@v4
        with:
          path: ${{ env.INDEX_DIR }}
          key: rfcindex-${{ hashFiles('data/index/manifest.json') }}
          restore-keys: |
            rfcindex-

      - name: Build index (if needed)
        run: |
          if [ ! -f "${INDEX_DIR}/sections.jsonl" ]; then
            ./scripts/sync_rfc_min.sh
            python scripts/build_index.py
          fi

      - name: Run evaluation suites
        env:
          ENABLE_DENSE: "0"
          AE_BIND_PORT: "8001"
          AE_INDEX_DIR: ${{ github.workspace }}/data/index
        run: |
          make eval-defs
          make eval-concepts
          make eval-trouble

      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-reports
          path: |
            eval_defs.json
            eval_concepts.json
            eval_trouble.json

  perf:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: eval
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ env.PIP_CACHE }}
          key: pip-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}

      - name: Install (editable)
        run: |
          python -m pip install -U pip
          python -m pip install -c constraints/ci.txt -e .

      - name: Cache RFC index
        uses: actions/cache@v4
        with:
          path: data/index
          key: rfc-index-${{ hashFiles('data/index/sections.jsonl') }}
          restore-keys: |
            rfc-index-

      - name: Build index (if needed)
        run: |
          mkdir -p data/index
          python scripts/build_index.py

      - name: Build Docker container
        run: docker build -t aev2:test .

      - name: Run container (background)
        run: |
          docker run -d --rm --name aev2 \
            -e AE_BIND_PORT=8001 \
            -e AE_INDEX_DIR=/app/data/index \
            -e ENABLE_DENSE=0 \
            -p 8001:8001 \
            -v "$PWD/data/index":/app/data/index \
            aev2:test
          # Wait for readiness
          for i in {1..30}; do
            curl -sf http://127.0.0.1:8001/readyz && break
            sleep 1
          done
          curl -sf http://127.0.0.1:8001/readyz

      - name: HTTP perf
        run: |
          python scripts/perf_http.py --host http://127.0.0.1:8001 --metrics --out perf_summary.json
          cat perf_summary.json

      - name: Stop container
        if: always()
        run: docker rm -f aev2 || true

      - name: Check metrics presence
        run: |
          if [ -f "perf_metrics.prom" ]; then
            echo "Checking core metrics presence..."
            grep -q "ae_http_request_latency_ms" perf_metrics.prom || (echo "ERROR: ae_http_request_latency_ms not found" && exit 1)
            grep -q "ae_router_intent_total" perf_metrics.prom || (echo "ERROR: ae_router_intent_total not found" && exit 1)
            grep -q "ae_query_latency_ms" perf_metrics.prom || (echo "ERROR: ae_query_latency_ms not found" && exit 1)
            grep -q "ae_cache_hits_total" perf_metrics.prom || (echo "ERROR: ae_cache_hits_total not found" && exit 1)
            echo "All core metrics present"
          else
            echo "WARNING: perf_metrics.prom not found, skipping metrics check"
          fi

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports
          path: |
            perf_http.json
            perf_metrics.prom
            perf_summary.json
